% Local IspellDict: en
\chapter{Theoretical Background}\label{ch02:theoretical}

\section{Image Segmentation}

Image segmentation is the process of dividing an image into different regions by grouping pixels and assigning each pixel a label. 
This step is an important part of many computer vision applications, such as detecting tumors in medical images or identifying 
pedestrians in autonomous driving. According to human visual perception, the identified regions are non-overlapping and meaningful 
- however, defining what exactly counts as a “meaningful” region can be difficult, as human perception is subjective and 
object boundaries are not always clear \citep{yu_techniques_2023}.

There are three common types of segmentation:

\textit{Semantic segmentation} assigns every pixel in an image a semantic label, such as “car” or “sky”.
\textit{Instance segmentation} separates individual objects within the same class, for example distinguishing several people in one image.
\textit{Panoptic segmentation} combines both approaches by providing pixel-wise class labels and also identifying individual object instances.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/segmentation_types.png}
    \caption{Types of image segmentation by \cite{kirillov_panoptic_2019}}
\end{figure}

Earlier approaches to image segmentation include algorithms such as k-means-clustering \citep{dhanachandra_image_2015}. Yet in recent years, deep learning models 
have significantly improved the segmentation effect and performance, therefore becoming the dominant method for solving segmentation 
tasks in complex environments \citep{minaee_image_2022}.

According to \cite{zhou_image_2024-1}, the above-described image segmentation methods fall into the category of generic image segmentation (GIS). 
The category of promptable image segmentation (PIS) extends GIS by specifying the target to segment through a prompt. 
This prompt can have various forms such as text, box or point.

\section{Salient Object Detection}
The human visual system pays more attention to certain parts in an image, a property known as saliency. 
Inspired by this mechanism, \textit{saliency detection} models aim to predict which regions in an image are most likely to attract human visual attention. 
These models typically provide saliency maps in form of heat maps, in which higher intensity values indicate regions detected to be more important \citep{ahmadi_context_2018}.

\textit{Salient Object Detection (SOD)} – also referred to as salient object segmentation \citep{borji_salient_2019} or saliency segmentation \citep{kakanopas_unified_2021} – 
goes one step further by segmenting the most salient object(s) of an image. SOD can be interpreted as a two-stage process: 
1) Detection of the most salient object and 2) Accurate segmentation of the region of that object. 
In contrast to general image segmentation, SOD focuses on segmenting only those objects that are (or that are predicted to be) most salient \citep{liu_learning_2011, borji_salient_2019}. 
Figure \ref{fig:sod_example} illustrates the difference between saliency detection and salient object detection.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.24\textwidth}
        \includegraphics[width=\linewidth]{figures/original_image_statue.jpg}
        \caption{}
        \label{fig:a}
    \end{subfigure}
    \begin{subfigure}{0.24\textwidth}
        \includegraphics[width=\linewidth]{figures/saliency_detection_example.jpeg}
        \caption{}
        \label{fig:b}
    \end{subfigure}
    \begin{subfigure}{0.24\textwidth}
        \includegraphics[width=\linewidth]{figures/sod_examlple.png}
        \caption{}
        \label{fig:c}
    \end{subfigure}

    \caption{(a) the original image, (b) saliency map \citep{alexander_kroner_visual_2025} (c) salient object detection mask generated using SAM3 guided by the eye-tracking data}
    \label{fig:sod_example}
\end{figure}



\section{Image Segmentation Models}

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/screenshot models.png}
    \caption{Overview of prominent image segmentation models}
    \label{fig:segmentation_models}
\end{figure}

\textcolor{red}{TODO: noch überarbeiten, hier nur erste Ideen:}

Figure \ref{fig:segmentation_models} provides an overview of prominent image segmentation models.

Only promptable segmentation models are suitable for our use case, as our pipeline requires point-based segmentation based on eye-tracking data. 
Classic semantic or instance segmentation models do not support point-based object selection. Among promptable models, SAM (and its successors SAM2 and SAM3) 
is the only widely used model that natively supports point prompts. Grounded-SAM and Florence-2 offer text-promptable capabilities but do not add any advantages 
for point-based segmentation. SEEM provides multimodal prompting but is less actively maintained compared to SAM2/SAM3. 
Therefore, SAM is the most suitable model for our use case.

+ Cited over 15.000 times, making it the de facto standard for domain specific implementations 

+ SAM3 release: Nov 20, 2025; in 2 weeks already 5.1k stars on github (more than SEEM in 2 years) - indicates strong community interest

+ SAM2: 52.8k stars on github


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main_thesis"
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
